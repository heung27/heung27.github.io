---
layout: post
title: 1. 카프카의 탄생과 빅데이터 파이프라인에서 카프카의 역할
date: 2022-06-04 17:02 +0900
categories: [Book, 아파치 카프카 애플리케이션 프로그래밍 with 자바]
tags: [아파치 카프카 애플리케이션 프로그래밍 with 자바, Kafka, Big Data]
---



'아파치 카프카 애플리케이션 프로그래밍 with 자바'를 읽고 정리한 내용을 포스팅합니다.

<br>

## 1. 카프카의 탄생

링크드인의 초기 운영 시에는 단방향 통신을 통해 소스 애플리케이션에서 타깃 애플리케이션으로 연동하는 소스코드를 작성했다. 시간이 지날수록 아키텍처가 거대해졌고, 소스 애플리케이션과 타깃 애플리케이션의 개수가 많아지면서 데이터를 전송하는 라인이 기하급수적으로 복잡해졌다.

이에따라 소스코드 및 버전 관리에서 이슈가 발생했고, 타깃 애플리케이션에 장애가 생길 경우 그 영향은 소스 애플리케이션에 그대로 전달되었다. 이런 데이터 파이프라인의 파편화를 개선하기 위해 연구한 결과 아파치 카프카가 탄생했다.

<br>

카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화했다. 카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화하여 커플링을 완화하였다.

카프카를 통해 전달할 수 있는 데이터 포맷은 사실상 제한이 없다. 직렬화, 역질렬화를 통해 ByteArray로 통신하기 때문에 자바에서 선언 가능한 모든 객체를 지원한다.

카프카 클러스터 중 일부 서버에 장애가 발생하더라도 데이터를 지속적으로 복제하기 때문에 안전하게 운영할 수 있다. 또한, 데이터를 묶음 단위로 처리하는 배치 전송을 통해 낮은 지연과 높은 데이터 처리량도 가지게 되었다.

<br>

## 2. 빅데이터 파이프라인에서 카프카의 역할

빅데이터로 적재되는 데이터의 종류는 스키마 기반의 정형 데이터부터 비정형 데이터까지 다양하다. 이런 방대한 양의 데이터를 기존의 데이터베이스로 관리하는 것은 불가능에 가깝다. 빅데이터를 저장하고 활용하기 위해서는 일단 생성되는 데이터를 모두 모으는 것이 중요한데, 이때 사용되는 개념이 ‘**데이터 레이크(data lake)**’다.

데이터 레이크는 이름에서 유추할 수 있는 것처럼 데이터가 모이는 저장 공간을 뜻한다. 데이터 웨어하우스와 다르게 필터링되거나 패키지화되지 않은 데이터가 저장된다는 점이 특징이다. 즉, 운영되는 서비스로부터 수집 가능한 모든 데이터를 모으는 것이다.

<br>

서비스에서 발생하는 데이터를 데이터 레이크로 모으려면 어떻게 해야 할까? 단순히 생각해보면 발생하는 데이터를 데이터 레이크에 직접 end-to-end 방식으로 넣을 수 있다. 그러나 이 방식은 서비스가 비대해지고 복잡해지면서 파편화되고 복잡도가 올라가는 문제점이 발생한다. 이를 해결하기 위해서 데이터를 추출하고 변경, 적재하는 과정을 묶은 데이터 파이프라인을 구축해야 한다.

end-to-end 방식의 데이터 수집 및 적재를 개선하고 안정성을 추구하며, 유연하면서도 확장 가능하게 자동화한 것을 ‘**데이터 파이프라인**'이라고 부른다. 그리고 데이터 파이프라인을 안정적이고 확장성 높게 운영하기 위한 좋은 방법 중 하나가 바로 아파치 카프카를 활용하는 것이다. 

아파치 카프카가 데이터 파이프라인으로 적합한 이유는 다음과 같다.

### 높은 처리량

- 카프카는 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송한다. 많은 양의 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는 데에 적합하다.
- 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬처리할 수 있다. 파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간당 데이터 처리량을 늘리는 것이다.

### 확장성

- 카프카는 데이터가 얼마나 들어올지 예측하기 어려운 가변적인 환경에서 안정적으로 확장 가능하도록 설계되었다. 데이터가 적을 때는 카프카 클러스터의 브로커를 최소한의 개수로 운영하다가 데이터가 많아지면 클러스터의 브로커 개수를 자연스럽게 늘려 scale-out할 수 있다. 반대로 데이터 개수가 적어지고 추가 서버들이 더는 필요 없어지면 브로커 개수를 줄여 scale-in할 수 있다.

### 영속성

- 영속성이란 데이터를 생성한 프로그램이 종료되더라도 사라지지 않는 데이터의 특성을 뜻한다. 카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다. 때문에 브로커 애플리케이션이 장애 발생으로 인해 급작스럽게 종료되더라도 프로세스를 재시작하여 안전하게 데이터를 다시 처리할 수 있다.

### 고가용성

- 클러스터로 이루어진 카프카는 데이터의 replication(복제)을 통해 고가용성의 특징을 가지게 되었다. 프로듀서로 전송받은 데이터를 여러 브로커 중 1대의 브로커에만 저장하는 것이 아니라 또 다른 브로커에도 저장하는 것이다. 한 브로커에 장애가 발생하더라도 복제된 데이터가 나머지 브로커에 저장되어 있으므로 지속적으로 데이터 처리가 가능하다.
- 추가로 on-premise 환경의 서버 랙 또는 public cloud의 리전 단위 장애에도 데이터를 안전하게 복제할 수 있는 브로커 옵션들이 준비되어 있다.
